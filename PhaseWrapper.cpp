//Steps:-
//1.For each pixel in all 3 captured images:-
//1.Compute the wrapped phase value and multiply it with 155 to map it to the gray-scale value.
//Save the image.

#include "/home/pranav/Desktop/PROJECT_GLOBAL/global_cv.h"
////////////////////////////////////////////////////////////////////////////Global variables.
extern int number_of_patterns_fringe;
extern char filename[150];
extern int pattern_type;
extern float (*wrapped_phi_vertical)[Camera_imageheight];
extern float (*wrapped_phi_horizontal)[Camera_imageheight];

IplImage**gray_captured_images;
IplImage*wrapped_phase_image;

extern int (*valid_map_vertical)[Camera_imageheight];
extern int (*valid_map_horizontal)[Camera_imageheight];

int (*valid_map_local)[Camera_imageheight]; //will point to the valid map in current consideration.
float (*wrapped_phi)[Camera_imageheight];

//bool visited[Camera_imagewidth][Camera_imageheight];//It will show which pixels are already visited in region growing approach.

extern int (*selected_region)[Camera_imageheight];


//This function will read the captured images of projected pattern for wrapping.
void read_image(int pattern_type)
{
    gray_captured_images=new IplImage*[number_of_patterns_fringe];
    //Lets give space to gray images first.
    for(int j=0; j<number_of_patterns_fringe; j++)
        gray_captured_images[j]=cvCreateImage(cvSize(Camera_imagewidth,Camera_imageheight),IPL_DEPTH_8U,1);

    for(int i=0; i<number_of_patterns_fringe; i++)
    {
        if(pattern_type==0)
            sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Vertical/Undistorted/Captured_image_%d.bmp",i);

        if(pattern_type==1)
            sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Horizontal/Undistorted/Captured_image_%d.bmp",i);

        gray_captured_images[i]=cvLoadImage(filename,CV_LOAD_IMAGE_GRAYSCALE);//those generated by 'project_image' module.

        if(pattern_type==0)
            sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Vertical/Undistorted/Gray_captured_image_%d.bmp",i);

        if(pattern_type==1)
            sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Horizontal/Undistorted/Gray_captured_image_%d.bmp",i);

        cvSaveImage(filename,gray_captured_images[i]);
    }



    return;
}




//this is another criteria to eliminate shadow+background.
void check_I_mod_criteria(int pattern_type)
{

//Lets load the image.
    if(pattern_type==0)
        sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Vertical/Original/Captured_image_0.bmp");
    if(pattern_type==1)
        sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Horizontal/Original/Captured_image_0.bmp");

    IplImage*test_image=cvLoadImage(filename);



//initializing valid map.
    for(int i=0; i<Camera_imageheight; i++)
        for(int j=0; j<Camera_imagewidth; j++)
        {
            valid_map_local[j][i]=0;
        }
    /*
    if((number_of_patterns_fringe==3))
    {
        float t1=0.0,t2=0.0;
        CvMat*t3=cvCreateMat(Camera_imageheight,Camera_imagewidth,CV_32FC1);//will contain 'gamma' for background+shadow elimination.

        for(int row=0; row<Camera_imageheight; row++)
            for(int col=0; col<Camera_imagewidth; col++)
            {
                t1=sqrtf(3.0*pow(((unsigned char)gray_captured_images[0]->imageData[row*gray_captured_images[0]->widthStep+col]-(unsigned char)gray_captured_images[2]->imageData[row*gray_captured_images[2]->widthStep+col]),2.0)+pow((2.0*(unsigned char)gray_captured_images[1]->imageData[row*gray_captured_images[1]->widthStep+col]-(unsigned char)gray_captured_images[0]->imageData[row*gray_captured_images[0]->widthStep+col]-(unsigned char)gray_captured_images[2]->imageData[row*gray_captured_images[2]->widthStep+col]),2.0));
                t2=(float)((unsigned char)gray_captured_images[0]->imageData[row*gray_captured_images[0]->widthStep+col]+(unsigned char)gray_captured_images[1]->imageData[row*gray_captured_images[1]->widthStep+col]+(unsigned char)gray_captured_images[2]->imageData[row*gray_captured_images[2]->widthStep+col]);
                CV_MAT_ELEM(*t3,float,row,col)=t1/t2;

                if((CV_MAT_ELEM(*t3,float,row,col)>0.01) && (selected_region[col][row]==1))
                {

                    cvCircle(test_image,cvPoint(col,row),1,cvScalar(0,0,0));
                    valid_map_local[col][row]=1;
                }
            }

    }*/

    if((number_of_patterns_fringe==4) || (number_of_patterns_fringe==3))
    {
        for(int i=0; i<Camera_imageheight; i++)
            for(int j=0; j<Camera_imagewidth; j++)
                if(selected_region[j][i]==1)
                {
                    valid_map_local[j][i]=1;

                }
    }

    /*  if(number_of_patterns_fringe==5)
      {
          for(int i=0;i<Camera_imageheight;i++)
          for(int j=0;j<Camera_imagewidth;j++)
          if(selected_region[j][i]==1)
          {
              valid_map_local[j][i]=1;

          }

      }

    */
///////////////////////////////////////////////////////////////////////////////////////

    if(pattern_type==0)
        cvSaveImage("Stage_1_vertical.bmp",test_image);
    if(pattern_type==1)
        cvSaveImage("Stage_2_horizontal.bmp",test_image);

    //De-allocate...
    cvReleaseImage(&test_image);


    return;

}






//Details:-Following function will wrap the phase using captured images.
void create_wrapped_phase(int pattern_type)
{
    float t1=0.0,t2=0.0;
    float t3=0.0;


//Lets allocate memory to the wrapped_phase image.
    wrapped_phase_image=cvCreateImage(cvSize(Camera_imagewidth,Camera_imageheight),IPL_DEPTH_8U,1);
    cvSet(wrapped_phase_image,cvScalar(0));//Blank out image.

//for 3 fringe technique:
    if(number_of_patterns_fringe==3)
    {

        for(int row_no=0; row_no<Camera_imageheight; row_no++)
            for(int col_no=0; col_no<Camera_imagewidth; col_no++)
            {
                if(valid_map_local[col_no][row_no]==1)//i.e.,not background or shadow.
                {
                    //printf("I1=%u\tI1=%u\tI3=%u\n",(unsigned char)gray_captured_images[0]->imageData[row_no*gray_captured_images[0]->widthStep+col_no],(unsigned char)gray_captured_images[1]->imageData[row_no*gray_captured_images[1]->widthStep+col_no],(unsigned char)gray_captured_images[1]->imageData[row_no*gray_captured_images[1]->widthStep+col_no]);
                    t1=/*sqrtf(3.0)*(*/(float)((unsigned char)gray_captured_images[0]->imageData[row_no*gray_captured_images[0]->widthStep+col_no])-(float)((unsigned char)gray_captured_images[2]->imageData[row_no*gray_captured_images[2]->widthStep+col_no]);//);
                    t2=2.0*((float)((unsigned char)gray_captured_images[1]->imageData[row_no*gray_captured_images[1]->widthStep+col_no]))-(float)((unsigned char)gray_captured_images[0]->imageData[row_no*gray_captured_images[0]->widthStep+col_no])-(float)((unsigned char)gray_captured_images[2]->imageData[row_no*gray_captured_images[2]->widthStep+col_no]);


                    wrapped_phi[col_no][row_no]=atan2(t1,t2);//this function will return the wrapped phase mapped between -pi to +pi.

//Lets make this wrapped phase value visible!!
                    t3=128.0f+127.0f*(wrapped_phi[col_no][row_no]/(Pi));
                    wrapped_phase_image->imageData[row_no*wrapped_phase_image->widthStep+col_no]=(unsigned char)(t3);
//Problem:-how to store 'float' values into image and to read it correctly?????
                }

            }

    }

    //for 4 fringe technique
    if(number_of_patterns_fringe==4)
    {
        for(int h=0; h<Camera_imageheight; h++)
            for(int w=0; w<Camera_imagewidth; w++)
            {
                if(valid_map_local[w][h]==1)
                {
                    t1=(float)((unsigned char)gray_captured_images[3]->imageData[h*gray_captured_images[3]->widthStep+w])-(float)((unsigned char)gray_captured_images[1]->imageData[h*gray_captured_images[1]->widthStep+w]);
                    t2=(float)((unsigned char)gray_captured_images[0]->imageData[h*gray_captured_images[0]->widthStep+w])-(float)((unsigned char)gray_captured_images[2]->imageData[h*gray_captured_images[2]->widthStep+w]);

                    wrapped_phi[w][h]=atan2(t1,t2);
                    t3=127.0f+128.0f*(wrapped_phi[w][h]/(Pi));

                    wrapped_phase_image->imageData[h*wrapped_phase_image->widthStep+w]=(unsigned char)(t3);
                }
            }
    }




    //for 5 fringe technique(HARIHARAN'S ALGORITHM)
    if(number_of_patterns_fringe==5)
    {
        for(int h=0; h<Camera_imageheight; h++)
            for(int w=0; w<Camera_imagewidth; w++)
            {
                if(valid_map_local[w][h]==1)
                {
                    t1=2.0*(/*sinf(2.0*Pi/5.0))(*/(float)((unsigned char)gray_captured_images[1]->imageData[h*gray_captured_images[1]->widthStep+w])-(float)((unsigned char)gray_captured_images[3]->imageData[h*gray_captured_images[3]->widthStep+w]));
                    t2=2.0*(float)((unsigned char)gray_captured_images[2]->imageData[h*gray_captured_images[2]->widthStep+w])-(float)((unsigned char)gray_captured_images[0]->imageData[h*gray_captured_images[0]->widthStep+w])-(float)((unsigned char)gray_captured_images[4]->imageData[h*gray_captured_images[4]->widthStep+w]);

                    wrapped_phi[w][h]=atan2f(t1,t2);
                    t3=127.0+128.0*(wrapped_phi[w][h]/(Pi));
                    wrapped_phase_image->imageData[h*wrapped_phase_image->widthStep+w]=(unsigned char)t3;

                }
            }



    }





//Done!!
    return;

}
//'wrapped_phase_image' contains the wrapped phase.





//Details:-Following function will save the wrapped phase in image format.
//CAUTION:-DO NOT USE THIS IMAGE FOR COMPUTATION PURPOSE AS IT IS MORE ERRONEOUS DUE TO QUANTIZATION OF PHASE VALUE TO 156 LEVELS!!
void save_wrapped_image(int pattern_type)
{

    bool (*visited_pixel)[Camera_imageheight]=new bool[Camera_imagewidth][Camera_imageheight];


    for(int g=0; g<1; g++) //running it 1 times for better boundary removal.
    {

        for(int i=0; i<Camera_imagewidth; i++)
            for(int j=0; j<Camera_imageheight; j++)
                visited_pixel[i][j]=false;  //Assuming none is visited.(initially)


        if(pattern_type==0)
        {
            sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Wrapped_phase_images/Vertical/Wrapped_phase_image.bmp");

            //Criteria:Any pixel with invalid neighbour is invalid:Next jump over it(to avoid complete black out).
            for(int y=1; y<Camera_imageheight-1; y++)
                for(int u=1; u<Camera_imagewidth-1; u++)
                {

                    if(((valid_map_local[u-1][y-1]!=1) && (visited_pixel[u-1][y-1]==false))||((valid_map_local[u][y-1]!=1) && (visited_pixel[u][y-1]==false))||((valid_map_local[u+1][y-1]!=1) && (visited_pixel[u+1][y-1]==false))||((valid_map_local[u-1][y]!=1) && (visited_pixel[u-1][y]==false))||((valid_map_local[u+1][y]!=1) && (visited_pixel[u+1][y]==false))||((valid_map_local[u-1][y+1]!=1) && (visited_pixel[u-1][y+1]==false))||((valid_map_local[u][y+1]!=1) && (visited_pixel[u][y+1]==false))||((valid_map_local[u+1][y+1]!=1) && (visited_pixel[u+1][y+1]==false)))
                    {
                        valid_map_local[u][y]=0;
                        visited_pixel[u][y]=true;
                        wrapped_phase_image->imageData[y*wrapped_phase_image->widthStep+u]=0;
                    }



                }

            /*
                        ///Lets see the presence of sinusoidal nature in captured patterns:
                        IplImage*sinusoidal_fringe_image=cvCreateImage(cvSize(Camera_imagewidth,Camera_imageheight),IPL_DEPTH_8U,1);
                        int t=0;
                        cvSet(sinusoidal_fringe_image,cvScalar(0));
                        for(int r=0; r<Camera_imageheight; r++)
                            for(int c=0; c<Camera_imagewidth; c++)
                            {
                                t=(unsigned char)gray_captured_images[0]->imageData[r*gray_captured_images[0]->widthStep+c]+(unsigned char)gray_captured_images[1]->imageData[r*gray_captured_images[1]->widthStep+c]+(unsigned char)gray_captured_images[1]->imageData[r*gray_captured_images[1]->widthStep+c];
                                sinusoidal_fringe_image->imageData[r*sinusoidal_fringe_image->widthStep+c]=(unsigned char)((unsigned char)gray_captured_images[0]->imageData[r*gray_captured_images[0]->widthStep+c]-(unsigned char)t);


                            }

                        cvSaveImage("sinusoid0.bmp",sinusoidal_fringe_image);

            */

        }


        if(pattern_type==1)
        {
            sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Wrapped_phase_images/Horizontal/Wrapped_phase_image.bmp");

            for(int y=1; y<Camera_imageheight-1; y++)
                for(int u=1; u<Camera_imagewidth-1; u++)
                {

                    if(((valid_map_local[u-1][y-1]!=1) && (visited_pixel[u-1][y-1]==false))||((valid_map_local[u][y-1]!=1) && (visited_pixel[u][y-1]==false))||((valid_map_local[u+1][y-1]!=1) && (visited_pixel[u+1][y-1]==false))||((valid_map_local[u-1][y]!=1) && (visited_pixel[u-1][y]==false))||((valid_map_local[u+1][y]!=1) && (visited_pixel[u+1][y]==false))||((valid_map_local[u-1][y+1]!=1) && (visited_pixel[u-1][y+1]==false))||((valid_map_local[u][y+1]!=1) && (visited_pixel[u][y+1]==false))||((valid_map_local[u+1][y+1]!=1) && (visited_pixel[u+1][y+1]==false)))
                    {
                        valid_map_local[u][y]=0;
                        visited_pixel[u][y]=true;
                        wrapped_phase_image->imageData[y*wrapped_phase_image->widthStep+u]=0;
                    }


                }

            /*
                        ///Lets see the presence of sinusoidal nature in captured patterns:
                        IplImage*sinusoidal_fringe_image=cvCreateImage(cvSize(Camera_imagewidth,Camera_imageheight),IPL_DEPTH_8U,1);
                        int t=0;
                        cvSet(sinusoidal_fringe_image,cvScalar(0));
                        for(int r=0; r<Camera_imageheight; r++)
                            for(int c=0; c<Camera_imagewidth; c++)
                            {
                                if(valid_map_local[c][r]==1)
                                {
                                    t=(unsigned char)gray_captured_images[0]->imageData[r*gray_captured_images[0]->widthStep+c]+(unsigned char)gray_captured_images[1]->imageData[r*gray_captured_images[1]->widthStep+c]+(unsigned char)gray_captured_images[1]->imageData[r*gray_captured_images[1]->widthStep+c];
                                    sinusoidal_fringe_image->imageData[r*sinusoidal_fringe_image->widthStep+c]=(unsigned char)((unsigned char)gray_captured_images[0]->imageData[r*gray_captured_images[0]->widthStep+c]-(unsigned char)t);
                                }

                                else
                                    sinusoidal_fringe_image->imageData[r*sinusoidal_fringe_image->widthStep+c]=0;
                                //printf()
                            }

                        cvSaveImage("sinusoid1.bmp",sinusoidal_fringe_image);
            */

        }

    }

    cvSaveImage(filename,wrapped_phase_image);





    if(pattern_type==0)
        sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Vertical/Original/Captured_image_0.bmp");

    if(pattern_type==1)
        sprintf(filename,"/home/pranav/Desktop/M_tech_project_console/Captured_patterns/Fringe_patterns/Horizontal/Original/Captured_image_0.bmp");

    IplImage*test_image=cvLoadImage(filename);

//Image after stage-1 filtering.
    for(int row=0; row<Camera_imageheight; row++)
        for(int col=0; col<Camera_imagewidth; col++)
            if(valid_map_local[col][row]!=1)
                cvCircle(test_image,cvPoint(col,row),1,cvScalar(0,0,0));

    if(pattern_type==0)
        cvSaveImage("Stage_1_vertical.bmp",test_image);

    if(pattern_type==1)
        cvSaveImage("Stage_2_horizontal.bmp",test_image);

    cvReleaseImage(&test_image);
    /*
    if(pattern_type==0)
       {//Testing DFT of wrapped_phase
       CvMat*src_mat=cvCreateMat(Camera_imageheight,Camera_imagewidth,CV_31FC1);
       CvMat*dst_mat=cvCreateMat(Camera_imageheight,Camera_imagewidth,CV_31FC1);

       for(int r=0;r<Camera_imageheight;r++)
       for(int c=0;c<Camera_imagewidth;c++)
       CV_MAT_ELEM(*src_mat,float,r,c)=(float)(wrapped_phi_vertical[c][r]);


       cvDFT(src_mat,dst_mat,CV_DXT_FORWARD);

      IplImage*dft=cvCreateImage(cvSize(Camera_imagewidth,Camera_imageheight),IPL_DEPTH_8U,1);

      for(int r=0;r<Camera_imageheight;r++)
      for(int c=0;c<Camera_imagewidth;c++)
      dft->imageData[r*dft->widthStep+c]=(unsigned char)(logf(CV_MAT_ELEM(*dst_mat,float,r,c)));

      cvSaveImage("dft.bmp",dft);
       }
    */
    //Done!!
    return;

}


//Details:-EXTERNAL INTERFACE.
void compute_wrapped_phase(int pattern_type)
{



    //Lets make 'valid_map' point to current pattern type's valid_map.
    if(pattern_type==0)
    {
        valid_map_vertical=new int[Camera_imagewidth][Camera_imageheight];

        valid_map_local=valid_map_vertical;

        wrapped_phi_vertical=new float[Camera_imagewidth][Camera_imageheight];


        wrapped_phi=wrapped_phi_vertical;
    }

    if(pattern_type==1)
    {
        valid_map_horizontal=new int[Camera_imagewidth][Camera_imageheight];
        valid_map_local=valid_map_horizontal;
        wrapped_phi_horizontal=new float[Camera_imagewidth][Camera_imageheight];
        wrapped_phi=wrapped_phi_horizontal;

    }






    read_image(pattern_type);//read the captured images.
    //generate_difference_map();
    check_I_mod_criteria(pattern_type);
    //following function will get the coordinates of point clicked over by user to be used as starting point for region growing.



    //cvReleaseVideoWriter(&video_writer);
    create_wrapped_phase(pattern_type);//wrap the phase,NOTE this function is independant of pattern type.


    save_wrapped_image(pattern_type);//save the phase image.


    ///TESTING FOR WAVINESS IN THE OUTPUT OF WRAPPED PHASE.
    //Show a image of wrapped phase
    // cvNamedWindow("Wrapped phase inspection")
    //Allow user to select a region
    //Show correspondig set of wrapped phase values.





    //Lets do the deallocation...
    cvReleaseImage(gray_captured_images);
    cvReleaseImage(&wrapped_phase_image);




    //Done!!
    return;
}

